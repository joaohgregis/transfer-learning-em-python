# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bJKl5p4cCA-UCCWVd2Q6Y6OgLdI91ee9
"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import os
!wget https://download.microsoft.com/download/3/E/1/3E1EAB6A-38DA-4A68-AF55-7345C5A996B1/kagglecatsanddogs_5340.zip
!unzip -q kagglecatsanddogs_5340.zip -d ./dataset
!ls dataset

base_dir = './dataset/PetImages'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

# Criar geradores de dados
datagen = ImageDataGenerator(
    rescale=1.0/255,
    validation_split=0.2,  # 20% para validação
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='validation'
)

# Carregar o modelo base pré-treinado
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(150, 150, 3),
    include_top=False,
    weights='imagenet'
)

# Congelar as camadas do modelo base
base_model.trainable = False

# Adicionar camadas personalizadas no topo
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')  # Saída binária (gatos e cachorros)
])

# Compilar o modelo
model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Resumo do modelo
model.summary()

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    epochs=10
)

# Avaliar o modelo
loss, accuracy = model.evaluate(validation_generator)
print(f"Loss: {loss}")
print(f"Accuracy: {accuracy}")

# Gráficos de desempenho
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs, acc, label='Acurácia no Treinamento')
plt.plot(epochs, val_acc, label='Acurácia na Validação')
plt.title('Acurácia')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, loss, label='Loss no Treinamento')
plt.plot(epochs, val_loss, label='Loss na Validação')
plt.title('Loss')
plt.legend()

plt.show()

model.save('transfer_learning_model.h5')